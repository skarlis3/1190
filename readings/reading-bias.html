<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Readings & Videos on Bias | ENGL 1190</title>
  <link rel="stylesheet" href="/style.css" />
  <link rel="icon" href="/1190icon.png" type="image/x-icon">
  <style>
    .reading-section {
      margin: 3em 0;
      padding: 2em 0;
      border-top: 1px solid rgba(255, 255, 255, 0.1);
    }

    .reading-section:first-of-type {
      border-top: none;
      padding-top: 0;
    }

    .bias-card {
      background: rgba(255, 255, 255, 0.03);
      border: 1px solid rgba(255, 255, 255, 0.1);
      border-radius: 8px;
      padding: 1.5em;
      margin: 1.5em 0;
      transition: background 0.2s ease, border-color 0.2s ease;
    }

    .bias-card:hover {
      background: rgba(255, 255, 255, 0.05);
      border-color: rgba(255, 255, 255, 0.2);
    }

    .bias-card h3 {
      margin-top: 0;
      color: #a8c7fa;
    }

    .bias-card strong {
      color: #c9b8f5;
    }
  </style>
</head>
<body>
  <div id="page-content">
    <!-- start of page content -->

    <h1>1.3  Readings & Videos on Bias</h1>

    <h2>Table of Contents</h2>
    <ul>
      <li>Believe by The Oatmeal</li>
      <li>Common Biases</li>
      <li>Inclusion, Exclusion, Illusion and Collusion</li>
    </ul>

    <div class="reading-section">
      <h2>Believe by The Oatmeal</h2>
      <p>This reading is a webcomic that can be found at the following links:</p>

      <h3>Original Version</h3>
      <p><a href="https://theoatmeal.com/comics/believe">https://theoatmeal.com/comics/believe</a></p>

      <h3>Clean Version</h3>
      <p>If swearing bothers you, the "clean version" can be read instead.</p>
      <p><a href="https://theoatmeal.com/comics/believe_clean">https://theoatmeal.com/comics/believe_clean</a></p>

      <h3>Text-only Version</h3>
      <p>If you need a screenreader-friendly version of this comic, please email me and I will send it to you. I've created a text-only version of the comic for accessibility purposes, but since this comic is under copyright, I cannot publicly post the comic on our class website.</p>
    </div>

    <div class="reading-section">
      <h2>Common Biases</h2>
      <p>BY-NC-ND <a href="http://www.yourbias.is/">www.yourbias.is</a></p>

      <div class="bias-card">
        <h3>Confirmation Bias</h3>
        <p><strong>You favor things that confirm your existing beliefs.</strong></p>

        <p>We are primed to see and agree with ideas that fit our preconceptions, and to ignore and dismiss information that conflicts with them. You could say that this is the mother of all biases, as it affects so much of our thinking through motivated reasoning. To help counteract its influence we ought to presume ourselves wrong until proven right.</p>

        <p>Think of your ideas and beliefs as software you're actively trying to find problems with rather than things to be defended. "The first principle is that you must not fool yourself â€“ and you are the easiest person to fool." - Richard Feynman</p>

        <p><strong>Further reading:</strong></p>
        <p><a href="https://en.wikipedia.org/wiki/Confirmation_bias">Wikipedia</a> | <a href="https://yourbias.is/Thinking,%20Fast%20and%20Slow">Thinking, Fast and Slow</a></p>
      </div>

      <div class="bias-card">
        <h3>Belief Bias</h3>
        <p><strong>If a conclusion supports your existing beliefs, you'll rationalize anything that supports it.</strong></p>

        <p>It's difficult for us to set aside our existing beliefs to consider the true merits of an argument. In practice this means that our ideas become impervious to criticism, and are perpetually reinforced. Instead of thinking about our beliefs in terms of 'true or false' it's probably better to think of them in terms of probability. For example we might assign a 95%+ chance that thinking in terms of probability will help us think better, and a less than 1% chance that our existing beliefs have no room for any doubt. Thinking probabalistically forces us to evaluate more rationally.</p>

        <p>A useful thing to ask is 'when and how did I get this belief?' We tend to automatically defend our ideas without ever really questioning them.</p>

        <p><strong>Further reading:</strong></p>
        <p><a href="https://en.wikipedia.org/wiki/Belief_bias">Wikipedia</a></p>
      </div>

      <div class="bias-card">
        <h3>The Barnum Effect</h3>
        <p><strong>You see personal specifics in vague statements by filling in the gaps.</strong></p>

        <p>Because our minds are given to making connections, it's easy for us to take nebulous statements and find ways to interpret them so that they seem specific and personal. The combination of our egos wanting validation with our strong inclination to see patterns and connections means that when someone is telling us a story about ourselves, we look to find the signal and ignore all the noise.</p>

        <p>Psychics, astrologers and others use this bias to make it seem like they're telling you something relevant. Consider how things might be interpreted to apply to anyone, not just you.</p>

        <p><strong>Further reading:</strong></p>
        <p><a href="https://en.wikipedia.org/wiki/Barnum_effect">Wikipedia</a></p>
      </div>

      <div class="bias-card">
        <h3>In-group Bias</h3>
        <p><strong>You unfairly favor those who belong to your group.</strong></p>

        <p>We presume that we're fair and impartial, but the truth is that we automatically favor those who are most like us, or belong to our groups. This blind tribalism has evolved to strengthen social cohesion, however in a modern and multicultural world it can have the opposite effect.</p>

        <p>Try to imagine yourself in the position of those in out-groups; whilst also attempting to be dispassionate when judging those who belong to your in-groups.</p>

        <p><strong>Further reading:</strong></p>
        <p>Wikipedia</p>
      </div>

      <div class="bias-card">
        <h3>The Backfire Effect</h3>
        <p><strong>When some aspect of your core beliefs is challenged, it can cause you to believe even more strongly.</strong></p>

        <p>We can experience being wrong about some ideas as an attack upon our very selves, or our tribal identity. This can lead to motivated reasoning which causes a reinforcement of beliefs, despite disconfirming evidence. Recent research shows that the backfire effect certainly doesn't happen all the time. Most people will accept a correction relating to specific facts, however the backfire effect may reinforce a related or 'parent' belief as people attempt to reconcile a new narrative in their understanding.</p>

        <p>"It ain't what you don't know that gets you into trouble. It's what you know for sure that just ain't so." - Mark Twain</p>

        <p><strong>Further reading:</strong></p>
        <p>You Are Now Less Dumb</p>
      </div>
    </div>

    <div class="reading-section">
      <h2>Inclusion, Exclusion, Illusion and Collusion</h2>
      <p>Helen Turnbull at TEDxDelrayBeach</p>

      <div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; margin: 2em 0;">
        <iframe style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;" src="https://www.youtube.com/embed/zdV8OpXhl2g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </div>
    </div>

    <!-- end of page content -->
  </div>

  <!-- main navigation and page scripts -->
  <script src="/nav.js" defer></script>
  <script src="/footer.js" defer></script>
</body>
</html>
